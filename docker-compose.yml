services:
  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    ports:
      - "${CLIENT_PORT:-8501}:8501"
    depends_on:
      - server
    volumes:
      - ./client:/app
    environment:
      - STREAMLIT_SERVER_PORT=8501
      - SERVER_URL=${SERVER_URL}

  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    ports:
      - "${SERVER_PORT:-4000}:4000"
    volumes:
      - ./server:/app
    env_file:
      - .env
    environment:
      - FLASK_RUN_PORT=4000
      - FLASK_ENV=${FLASK_ENV}
      - FLASK_APP=${FLASK_APP:-server.py}
      - FIREBASE_BUCKET=${FIREBASE_BUCKET}
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data

  scheduler:
    build: .
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
               airflow scheduler"
    depends_on:
      - postgres

  webserver:
    build: .
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: airflow webserver
    depends_on:
      - scheduler

volumes:
  postgres_data: